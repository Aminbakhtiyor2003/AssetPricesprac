# AssetPricesprac

My Research Framework for Regime Intuition and Cross-Asset Pattern Recognition

This project represents my attempt to develop a disciplined framework for identifying historical analogs in cross-asset factor returns. The purpose was never to design a mechanical trading signal. Instead, the intent was to create structured intuition about how factor and style returns behave across different market regimes, focusing on directional consensus, relative rotations, and sequential dependencies that are not always obvious in raw time series.

The dataset originates from AQR, a firm with one of the most well-established research pedigrees in quantitative investing. Their factor-level data offers nearly a century of history, a rare combination of depth and credibility. I chose it both for its reliability and for the fact that AQR itself uses this data in its published research, which suggests a high degree of practical relevance. My objective was not to master every methodological nuance of factor construction, but to study their relationships over time. This work is about behavior, not definition; structure, not formula.

The model begins in the early 1980s. Although the data extends further back, I deliberately excluded the 1970s, particularly fixed income, because the Volcker tightening cycle introduced structural distortions that skewed similarity metrics. Post-1980 data offered a more stable foundation for pattern recognition.

For a given target month, the model searches for historical analogs using two approaches. The first is Euclidean distance, which captures magnitude differences and is sensitive to volatility. The second is Cosine similarity, which captures directionality independent of scale. Both methods typically produced overlapping matches, adding robustness to the exercise. Cosine similarity was particularly useful when directional relationships mattered more than amplitude, aligning with the project’s purpose of understanding return structures rather than absolute levels.

To simplify the noise in monthly returns, I discretized outcomes into three categories: positive, flat, and negative, using a ±0.2% threshold. This allowed for clearer base rate analysis while maintaining meaningful directional signals. The model then examined T+1 outcomes, meaning the month following each identified analog, to assess what happened next historically. Longer horizons are supported, but compounding uncertainty dilutes their reliability. The goal was not prediction, but to provide probabilistic anchors grounded in precedent.

For each factor, base rates were aggregated to show how often returns were positive, flat, or negative in the periods following similar configurations. These base rates do not represent trading signals. They serve as contextual reference points, quantifying the range of plausible outcomes under a given starting state. The philosophy here borrows from the reasoning framework described in Superforecasting. Anchoring blindly creates bias, but anchoring to rigorously selected historical precedent can be a disciplined starting point for judgment under uncertainty.

Contextual review is essential. Statistical match does not guarantee narrative coherence. Each set of analogs is manually examined for alignment in macroeconomic backdrop, investor positioning, and the presence of exogenous risks that might invalidate the comparison. Without this qualitative layer, models risk becoming numerically precise but contextually irrelevant. I treat historical similarity as a hypothesis generator, not as proof.

The limits of this approach are clear. Structural breaks, policy shocks, and behavioral shifts will always challenge models built on historical precedent. As Mark Twain observed, history may not repeat itself, but it often rhymes. This framework seeks to detect the rhymes without mistaking them for deterministic scripts.

Looking forward, several improvements are planned. Thresholds may be volatility-adjusted to better reflect regime-dependent noise levels. Alternative similarity metrics such as Mahalanobis distance or dynamic time warping may improve analog matching. Unsupervised learning methods could reduce manual bias and reveal higher-dimensional structure in factor behavior. Conditioning similarity on macro or sentiment variables could improve relevance and reduce noise. And as data extends through 2025, I plan to test whether the intuition derived from this process holds out of sample.

Ultimately, this project is not about precise forecasts. It is about improving reasoning under uncertainty. It is a way to think more systematically about regimes, factor interactions, and probabilistic outcomes. The goal is not to be exactly right, but to be structurally reasonable, to move closer to judgments that respect both history and its limits.

